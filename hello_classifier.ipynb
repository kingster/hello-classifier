{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9a825e72",
   "metadata": {},
   "source": [
    "# üì¶ 1. Install Dependencies\n",
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf315af0",
   "metadata": {},
   "source": [
    "# üìÇ 2. Load libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5af74632",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76879826",
   "metadata": {},
   "source": [
    "# üìÇ 2. Load intents.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c77d145f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>intent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>catch you later</td>\n",
       "      <td>goodbye</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>what is cryptex?</td>\n",
       "      <td>others</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>so long</td>\n",
       "      <td>goodbye</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>adios</td>\n",
       "      <td>goodbye</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>what is the meaning of life?</td>\n",
       "      <td>others</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>I'm confused</td>\n",
       "      <td>others</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            text   intent\n",
       "15               catch you later  goodbye\n",
       "37              what is cryptex?   others\n",
       "17                       so long  goodbye\n",
       "14                         adios  goodbye\n",
       "41  what is the meaning of life?   others\n",
       "33                  I'm confused   others"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Json Example\n",
    "# with open(\"../intents.json\", \"r\") as f:\n",
    "#     intents = json.load(f)\n",
    "# data = []\n",
    "# for intent, phrases in intents.items():\n",
    "#     for phrase in phrases:\n",
    "#         data.append({\"text\": phrase, \"intent\": intent})\n",
    "# df = pd.DataFrame(data)\n",
    "\n",
    "# CSV is simplers\n",
    "df = pd.read_csv(\"training_data.csv\")\n",
    "\n",
    "df.sample(6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2594e51b",
   "metadata": {},
   "source": [
    "# üè∑Ô∏è 3. Label Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d12a6db1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "{'classes_': array(['goodbye', 'greet', 'others', 'thank_you'], dtype=object)}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le = LabelEncoder()\n",
    "df[\"label\"] = le.fit_transform(df[\"intent\"])\n",
    "num_labels = len(le.classes_)\n",
    "\n",
    "print(num_labels)\n",
    "print(le.__dict__) # this sequence is important\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44ba5f60",
   "metadata": {},
   "source": [
    "# üî† 4. Tokenize Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3c73a13d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Volumes/Workspace/code/ai/hello-classifier/.venv/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "tokens = tokenizer(\n",
    "    list(df[\"text\"]),\n",
    "    truncation=True,\n",
    "    padding=True,\n",
    "    return_tensors=\"pt\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26f7a787",
   "metadata": {},
   "source": [
    "# üß± 5. Create Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c1b2729b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "class IntentDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: val[idx] for key, val in self.encodings.items()}\n",
    "        item[\"labels\"] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "dataset = IntentDataset(tokens, df[\"label\"].tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bda255f",
   "metadata": {},
   "source": [
    "# ü§ñ 6. Load BERT for Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "be2e7fc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertForSequenceClassification\n",
    "\n",
    "model = BertForSequenceClassification.from_pretrained(\n",
    "    \"bert-base-uncased\", \n",
    "    num_labels=len(le.classes_)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e71e41d",
   "metadata": {},
   "source": [
    "# üèãÔ∏è 7. Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ba2cf048",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Volumes/Workspace/code/ai/hello-classifier/.venv/lib/python3.13/site-packages/torch/utils/data/dataloader.py:683: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='220' max='220' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [220/220 00:25, Epoch 20/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1.256100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1.052700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.786800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.549800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.403500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.258200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>0.086000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.032400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>0.016500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.011100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>0.006800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.005900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>0.004600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>0.004100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.003500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.003300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>0.003200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.003200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>0.002900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.002900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>0.002900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>0.002800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "('intent_model/tokenizer_config.json',\n",
       " 'intent_model/special_tokens_map.json',\n",
       " 'intent_model/vocab.txt',\n",
       " 'intent_model/added_tokens.json')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import Trainer, TrainingArguments\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    per_device_train_batch_size=4,\n",
    "    num_train_epochs=20,\n",
    "    logging_dir='./logs',\n",
    "    logging_steps=10,\n",
    "    report_to=\"none\"\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=dataset\n",
    ")\n",
    "\n",
    "trainer.train()\n",
    "\n",
    "\n",
    "model.save_pretrained(\"intent_model\")\n",
    "tokenizer.save_pretrained(\"intent_model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1c245ba",
   "metadata": {},
   "source": [
    "# üíæ 8. Save Model and Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1172d0f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['label_encoder.pkl']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained(\"intent_model\")\n",
    "model = BertForSequenceClassification.from_pretrained(\"intent_model\")\n",
    "\n",
    "\n",
    "# Save Label Encoder\n",
    "joblib.dump(le, \"label_encoder.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d8ccd989",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "greet\n",
      "others\n"
     ]
    }
   ],
   "source": [
    "def predict_intent(text,  confidence_threshold=0.7):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    logits = outputs.logits\n",
    "    probabilities = torch.nn.functional.softmax(logits, dim=1)\n",
    "    max_prob, predicted = torch.max(probabilities, dim=1)\n",
    "\n",
    "     # If confidence is below threshold, return \"others\"\n",
    "    if max_prob.item() < confidence_threshold:\n",
    "        return \"others\"\n",
    "\n",
    "    # predicted = torch.argmax(logits, dim=1)\n",
    "    return le.inverse_transform(predicted.numpy())[0]\n",
    "\n",
    "# Try it!\n",
    "print(predict_intent(\"hiya!\"))            # ‚Üí greet\n",
    "print(predict_intent(\"tell me a joke\"))   # ‚Üí joke\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eb82da64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "others\n",
      "greet\n"
     ]
    }
   ],
   "source": [
    "print(predict_intent(\"what is tns audit store and how is it designed?\"))   # ‚Üí joke\n",
    "\n",
    "print(predict_intent(\"hi there!\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "865b46be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempting to export model from: /Volumes/Workspace/code/ai/hello-classifier/intent_model\n",
      "ONNX model and associated files will be saved in: /Volumes/Workspace/code/ai/hello-classifier/src/main/resources/intent_model_onnx\n",
      "Successfully exported ONNX model and associated files to: src/main/resources/intent_model_onnx\n",
      "The ONNX model file is: src/main/resources/intent_model_onnx/model.onnx\n",
      "Tokenizer files (e.g., vocab.txt, tokenizer_config.json) should also be in this directory.\n"
     ]
    }
   ],
   "source": [
    "from optimum.exporters.onnx import main_export\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "source_model_dir = \"intent_model\"\n",
    "\n",
    "# Define the output directory for the ONNX model and associated files\n",
    "onnx_output_dir = Path(\"src/main/resources/intent_model_onnx\")\n",
    "onnx_output_dir.mkdir(parents=True, exist_ok=True) # Ensure the directory exists\n",
    "\n",
    "\n",
    "print(f\"Attempting to export model from: {os.path.abspath(source_model_dir)}\")\n",
    "print(f\"ONNX model and associated files will be saved in: {os.path.abspath(onnx_output_dir)}\")\n",
    "\n",
    "\n",
    "\n",
    "try:\n",
    "    # Export the model.\n",
    "    # For BertForSequenceClassification, the task is \"text-classification\".\n",
    "    # The exporter will save 'model.onnx' and other files (tokenizer config, model config)\n",
    "    # into the onnx_output_dir.\n",
    "    main_export(\n",
    "        model_name_or_path=source_model_dir,\n",
    "        output=onnx_output_dir,  # Specify the directory for output\n",
    "        task=\"text-classification\",  # Standard task name for sequence classification models\n",
    "        # opset=12,  # Optional: specify a specific ONNX opset version. Defaults to a stable one.\n",
    "        # device=\"cpu\", # Optional: specify device for export ('cpu' or 'cuda')\n",
    "        # framework=\"pt\", # Optional: can be 'pt' (PyTorch) or 'tf' (TensorFlow). Usually auto-detected.\n",
    "    )\n",
    "    print(f\"Successfully exported ONNX model and associated files to: {onnx_output_dir}\")\n",
    "    print(f\"The ONNX model file is: {onnx_output_dir / 'model.onnx'}\")\n",
    "    print(f\"Tokenizer files (e.g., vocab.txt, tokenizer_config.json) should also be in this directory.\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred during ONNX export: {e}\")\n",
    "    print(f\"Please ensure that your '{source_model_dir}' directory contains all necessary files \"\n",
    "          f\"(e.g., pytorch_model.bin, config.json, vocab.txt, tokenizer_config.json).\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "aaa24201",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run and validate the onnx model\n",
    "import onnxruntime as ort\n",
    "\n",
    "\n",
    "model_path = \"src/main/resources/intent_model_onnx\"\n",
    "\n",
    " # Load ONNX model\n",
    "onnx_session = ort.InferenceSession(model_path+\"/model.onnx\")\n",
    "onnx_tokenizer = BertTokenizer.from_pretrained(model_path)\n",
    "\n",
    "# \n",
    "id2label = ['goodbye', 'greet', 'others', 'thank_you']\n",
    "\n",
    "\n",
    "def onnx_predict(text, confidence_threshold=0.7):\n",
    "        \n",
    "    # Tokenize input text\n",
    "    inputs = onnx_tokenizer(\n",
    "        text,\n",
    "        return_tensors=\"pt\",\n",
    "        truncation=True,\n",
    "        padding=True,\n",
    "        max_length=128\n",
    "    )\n",
    "\n",
    "    # Convert to numpy arrays\n",
    "    input_ids = inputs['input_ids'].numpy()\n",
    "    attention_mask = inputs['attention_mask'].numpy()\n",
    "    token_type_ids = inputs['token_type_ids'].numpy()  \n",
    "\n",
    "    # Prepare input for ONNX model\n",
    "    ort_inputs = {\n",
    "        'input_ids': input_ids,\n",
    "        'attention_mask': attention_mask,\n",
    "        'token_type_ids': token_type_ids\n",
    "    }\n",
    "\n",
    "    # Run inference\n",
    "    ort_outputs = onnx_session.run(None, ort_inputs)\n",
    "\n",
    "    # Get probabilities\n",
    "    logits = ort_outputs[0]\n",
    "    probabilities = torch.nn.functional.softmax(torch.tensor(logits), dim=1)\n",
    "\n",
    "    # Get prediction\n",
    "    max_prob, predicted = torch.max(probabilities, dim=1)\n",
    "\n",
    "    # Check confidence threshold\n",
    "    if max_prob.item() < confidence_threshold:\n",
    "        return \"others\"\n",
    "    \n",
    "    # Return predicted intent\n",
    "    return id2label[predicted.item()]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f6918280",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: hi there!\n",
      "Predicted Intent: greet\n",
      "\n",
      "Text: tell me a joke\n",
      "Predicted Intent: others\n",
      "\n",
      "Text: what is tns audit store and how is it designed?\n",
      "Predicted Intent: others\n",
      "\n",
      "Text: thank you very much\n",
      "Predicted Intent: thank_you\n",
      "\n"
     ]
    }
   ],
   "source": [
    " # Test some examples\n",
    "test_texts = [\n",
    "    \"hi there!\",\n",
    "    \"tell me a joke\",\n",
    "    \"what is tns audit store and how is it designed?\",\n",
    "    \"thank you very much\"\n",
    "]\n",
    "\n",
    "for text in test_texts:\n",
    "    intent = onnx_predict(text)\n",
    "    print(f\"Text: {text}\")\n",
    "    print(f\"Predicted Intent: {intent}\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
